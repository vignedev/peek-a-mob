import os
import argparse
from os import path
from utils import annotate_file, get_entity_bidict
import cv2 as cv
from multiprocessing import Pool
import random

RANDOM_TRAIN_RATIO=0.7
RANDOM_VALID_RATIO=0.2
RANDOM_TEST_RATIO=0.1 # ignored btw

def get_argv():
  parser = argparse.ArgumentParser()
  parser.add_argument(
    '-i', '--input',
    help='input folder where the quadrant-screenshots are located at',
    required=True
  )
  parser.add_argument(
    '-e', '--entities',
    help='location of entitites.json generated by the `minecraft_shader/generate_entittyprop.js`',
    required=True
  )
  parser.add_argument(
    '-o', '--output',
    help='output folder, where the images and their annotations are going to be',
    required=True
  )
  parser.add_argument(
    '-t', '--type',
    help='should this be a train, validation or test dataset. or sort/random_sort, which will spread them around in 70:20:10 ratio. random will randomize the order!',
    default='train',
    choices=['train', 'valid', 'test', 'sort', 'random_sort']
  )
  parser.add_argument(
    '-f', '--format',
    help='which format to output the annotations as, or rather what should the first two normalized coordinates represent\n'
         '(center: center of bounding box, bbox: top-left corner of bounding box)',
    choices=['center', 'bbox'],
    required=True
  )
  parser.add_argument(
    '-n', '--ncpu',
    help='how many threads to use for the conversion',
    type=int
  )
  parser.add_argument(
    '-d', '--debug',
    help='draws the bounding boxes onto cropped images (do not use for generating!!)',
    action='store_true'
  )
  parser.add_argument(
    '-x', '--extension',
    help='the file extension for the final images to use (eg. for images.png use "png")',
    default='png'
  )
  parser.add_argument(
    '-a', '--area_threshold',
    help='normalized area threshold, values below this would get filtered out (set to 0.0 to disable)',
    default=0.0,
    type=float
  )
  return parser.parse_args()

def create_from_image(filepath: str, _type: str, argv: argparse.Namespace):
  name = '.'.join(path.basename(filepath).split('.')[:-1])
  image, labels = annotate_file(filepath, format=argv.format, debug_draw=argv.debug, area_threshold=argv.area_threshold)

  cv.imwrite(path.join(argv.output, _type, 'images', f'{name}.{argv.extension}'), image)
  with open(path.join(argv.output, _type, 'labels', f'{name}.txt'), 'w') as hfile:
    hfile.write('\n'.join([ ' '.join([ str(w) for w in v ]) for v in labels ]))
  return filepath

def create_from_image_tuple(data: tuple[str, str, argparse.Namespace]):
  filepath, _type, argv = data
  return create_from_image(filepath, _type, argv)

if __name__ == '__main__':
  argv = get_argv()
  entity_bidict, entity_json = get_entity_bidict(argv.entities)

  # list of files
  files: list[tuple[str, str]] = [ (path.join(argv.input, file), argv.type) for file in os.listdir(argv.input) if os.path.isfile(path.join(argv.input, file)) ]
  n_files = len(files)

  # sorter
  if argv.type in ['sort', 'random_sort']:
    if argv.type == 'random_sort':
      random.shuffle(files)

    for i in range(n_files):
      _file, _type = files[i]
      ratio = (i+1) / n_files
      if ratio <= RANDOM_TRAIN_RATIO:
        files[i] = (_file, 'train')
      elif ratio <= (RANDOM_TRAIN_RATIO + RANDOM_VALID_RATIO):
        files[i] = (_file, 'valid')
      else:
        files[i] = (_file, 'test')

  # ensure that output dir structure exists
  os.makedirs(argv.output, exist_ok=True)
  for folder in ['train', 'valid', 'test']:
    os.makedirs(path.join(argv.output, folder, 'images'), exist_ok=True)
    os.makedirs(path.join(argv.output, folder, 'labels'), exist_ok=True)

  # write the intro yaml (if not existing)
  data_path = path.join(argv.output, 'data.yaml')
  if not path.exists(data_path) or True: # doesnt hurt much, right?
    with open(data_path, 'w') as file:
      file.write('\n'.join([
        f'train: train/images',
        f'val: valid/images',
        f'test: test/images',
        f'',
        f'nc: {len(entity_json)}',
        f'names: [{', '.join([ f'\'{ent}\'' for ent in entity_json ])}]'
      ]))

  # lets get the show on the f-cking road
  counter = 0
  pool = Pool(processes=argv.ncpu)
  for name in pool.imap_unordered( create_from_image_tuple, [ (_file, _type, argv) for _file, _type in files ]):
    counter += 1
    if counter == n_files or counter % 100 == 0:
      print(f'[i] finished ({counter}/{n_files}) {name}')