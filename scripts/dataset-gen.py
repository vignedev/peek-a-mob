import os
import argparse
from os import path
from utils import annotate_file, get_entity_bidict
import cv2 as cv
from multiprocessing import Pool

def get_argv():
  parser = argparse.ArgumentParser()
  parser.add_argument(
    '-i', '--input',
    help='input folder where the quadrant-screenshots are located at',
    required=True
  )
  parser.add_argument(
    '-e', '--entities',
    help='location of entitites.json generated by the `minecraft_shader/generate_entittyprop.js`',
    required=True
  )
  parser.add_argument(
    '-o', '--output',
    help='output folder, where the images and their annotations are going to be',
    required=True
  )
  parser.add_argument(
    '-t', '--type',
    help='should this be a train, validation or test dataset. or random, which will spread them around in 70:20:10 ratio',
    default='train',
    choices=['train', 'valid', 'test', 'random']
  )
  parser.add_argument(
    '-f', '--format',
    help='which format to output the annotations as, or rather what should the first two normalized coordinates represent\n'
         '(center: center of bounding box, bbox: top-left corner of bounding box)',
    choices=['center', 'bbox'],
    required=True
  )
  parser.add_argument(
    '-n', '--ncpu',
    help='how many threads to use for the conversion',
    type=int
  )
  parser.add_argument(
    '-d', '--debug',
    help='draws the bounding boxes onto cropped images (do not use for generating!!)',
    action='store_true'
  )
  return parser.parse_args()

def create_from_image(filepath: str, _type: str, argv: argparse.Namespace):
  name = '.'.join(path.basename(filepath).split('.')[:-1])
  image, labels = annotate_file(filepath, format=argv.format, debug_draw=argv.debug)

  cv.imwrite(path.join(argv.output, _type, 'images', f'{name}.png'), image)
  with open(path.join(argv.output, _type, 'labels', f'{name}.txt'), 'w') as hfile:
    hfile.write('\n'.join([ ' '.join([ str(w) for w in v ]) for v in labels ]))
  return filepath

def create_from_image_tuple(data: tuple[str, str, argparse.Namespace]):
  filepath, _type, argv = data
  return create_from_image(filepath, _type, argv)

if __name__ == '__main__':
  argv = get_argv()
  entity_bidict, entity_json = get_entity_bidict(argv.entities)

  # list of files
  files: list[str] = os.listdir(argv.input)
  n_files = len(files)

  # ensure that output dir structure exists
  os.makedirs(argv.output, exist_ok=True)
  for folder in ['train', 'val', 'test']:
    os.makedirs(path.join(argv.output, folder, 'images'), exist_ok=True)
    os.makedirs(path.join(argv.output, folder, 'labels'), exist_ok=True)

  # write the intro yaml (if not existing)
  data_path = path.join(argv.output, 'data.yaml')
  if not path.exists(data_path) or True: # doesnt hurt much, right?
    with open(data_path, 'w') as file:
      file.write('\n'.join([
        f'train: train/images',
        f'val: valid/images',
        f'test: test/images',
        f'',
        f'nc: {len(entity_json)}',
        f'names: [{', '.join([ f'\'{ent}\'' for ent in entity_json ])}]'
      ]))

  # lets get the show on the f-cking road
  counter = 0
  pool = Pool(processes=argv.ncpu)
  for name in pool.imap_unordered( create_from_image_tuple, [ (path.join(argv.input, file), argv.type, argv) for file in files ]):
    counter += 1
    if counter == n_files or counter % 100 == 0:
      print(f'[i] finished ({counter}/{n_files}) {name}')